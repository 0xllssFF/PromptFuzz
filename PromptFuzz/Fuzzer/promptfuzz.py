import os
import sys
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # for debugging

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from fastchat.model import add_model_args
import argparse
import pandas as pd
from gptfuzzer.fuzzer.selection import MCTSExploreSelectPolicy
from gptfuzzer.fuzzer.mutator import (
    MutateRandomSinglePolicy, OpenAIMutatorCrossOver, OpenAIMutatorExpand,
    OpenAIMutatorGenerateSimilar, OpenAIMutatorRephrase, OpenAIMutatorShorten)
from gptfuzzer.fuzzer import GPTFuzzer
from gptfuzzer.llm import OpenAILLM, LocalVLLM, LocalLLM, PaLM2LLM, ClaudeLLM
from PromptFuzz.utils import constants

import random
random.seed(100)
import logging
httpx_logger: logging.Logger = logging.getLogger("httpx")
# disable httpx logging
httpx_logger.setLevel(logging.WARNING)


def main(args):
    initial_seed = pd.read_csv(args.seed_path)['text'].tolist()

    openai_model = OpenAILLM(args.model_path, args.openai_key)

    
    save_path = f'./Results/{args.phase}/{args.mode}'
    if args.add_eos:
        save_path = f'./Results/{args.target_model}/GPTFuzzer_eos/{args.index}.csv'
    
    print("The save path is: ", save_path)

    fuzzer = GPTFuzzer(
        questions=questions,
        target=openai_model,
        predictor=roberta_model,
        initial_seed=initial_seed,
        mutate_policy=MutateRandomSinglePolicy([
            OpenAIMutatorCrossOver(openai_model), 
            OpenAIMutatorExpand(openai_model),
            OpenAIMutatorGenerateSimilar(openai_model),
            OpenAIMutatorRephrase(openai_model),
            OpenAIMutatorShorten(openai_model)],
            concatentate=True,
        ),
        select_policy=MCTSExploreSelectPolicy(),
        energy=args.energy,
        max_jailbreak=args.max_jailbreak,
        max_query=args.max_query,
        generate_in_batch=False,
    )

    fuzzer.run()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Fuzzing parameters')
    parser.add_argument('--index', type=int, default=0, help='The index of the target prompt')
    parser.add_argument('--phase', choices=['evaluate', 'focus'], default='test', help='The phase of the fuzzing process')
    parser.add_argument('--mode', choices=['hijack', 'extraction'], default='hijack', help='The mode of the fuzzing process')
    parser.add_argument('--openai_key', type=str, default=None, help='OpenAI API Key')
    parser.add_argument('--model_path', type=str, default='gpt-3.5-turbo-0125', help='target model path')
    parser.add_argument('--max_query', type=int, default=1000,
                        help='The maximum number of queries')
    parser.add_argument('--max_jailbreak', type=int,
                        default=1, help='The maximum jailbreak number')
    parser.add_argument('--energy', type=int, default=1,
                        help='The energy of the fuzzing process')
    parser.add_argument('--seed_selection_strategy', type=str,
                        default='round_robin', help='The seed selection strategy')
    parser.add_argument("--max-new-tokens", type=int, default=512)
    parser.add_argument("--seed_path", type=str,
                        default="datasets/prompts/GPTFuzzer.csv")
    add_model_args(parser)

    args = parser.parse_args()
    
    if args.openai_key is None:
        args.openai_key = constants.openai_key
    main(args)
